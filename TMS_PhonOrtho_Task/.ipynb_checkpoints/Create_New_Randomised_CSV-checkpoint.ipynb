{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sessions = [\"1\",\"2\",\"3\",\"4\"] # list all sessions here\n",
    "rw_contexts = [\"cvc_only\",\"metronome_only\",\"cvc_metronome\"]\n",
    "ff_contexts = [\"control\",\"control\"]\n",
    "\n",
    "for session in sessions:\n",
    "    start_path = \"/Users/nikola/NikolaCloud/Projects/Research Projects/2018 - UCSF/R01_Dyslexia_TMS/3_experiment/1_collection/TMS_PhonOrtho_Task\"\n",
    "    list1_path = \"/trial_list/old_randomisation/trials_ses\"+session+\"_run1.csv\"\n",
    "    list2_path = \"/trial_list/old_randomisation/trials_ses\"+session+\"_run2.csv\"\n",
    "    list3_path = \"/trial_list/old_randomisation/trials_ses\"+session+\"_run3.csv\"\n",
    "    list4_path = \"/trial_list/old_randomisation/trials_ses\"+session+\"_run4.csv\"\n",
    "    list5_path = \"/trial_list/old_randomisation/trials_ses\"+session+\"_run5.csv\"\n",
    "    list6_path = \"/trial_list/old_randomisation/trials_ses\"+session+\"_run6.csv\"\n",
    "\n",
    "    list1 = pd.read_csv(start_path+list1_path)\n",
    "    list2 = pd.read_csv(start_path+list2_path)\n",
    "    list3 = pd.read_csv(start_path+list3_path)\n",
    "    list4 = pd.read_csv(start_path+list4_path)\n",
    "    list5 = pd.read_csv(start_path+list5_path)\n",
    "    list6 = pd.read_csv(start_path+list6_path)\n",
    "\n",
    "    # pre TMS trials\n",
    "    oldPreTMS = pd.concat([list1,list2,list3])\n",
    "    \n",
    "    oldPreTMS_phonological = oldPreTMS.query(\"condition == 'phonological'\")\n",
    "    oldPreTMS_orthographic = oldPreTMS.query(\"condition == 'orthographic'\")\n",
    "    oldPreTMS_false_font = oldPreTMS.query(\"condition == 'false_font'\")\n",
    "    \n",
    "    oldPreTMS_phonological_matches = oldPreTMS_phonological.query(\"correct_resp == '3'\")\n",
    "    oldPreTMS_phonological_matches = oldPreTMS_phonological_matches.copy()\n",
    "    oldPreTMS_phonological_mismatches = oldPreTMS_phonological.query(\"correct_resp == '4'\")\n",
    "    oldPreTMS_phonological_mismatches = oldPreTMS_phonological_mismatches.copy()\n",
    "    \n",
    "    oldPreTMS_orthographic_matches = oldPreTMS_orthographic.query(\"correct_resp == '3'\")\n",
    "    oldPreTMS_orthographic_matches = oldPreTMS_orthographic_matches.copy()\n",
    "    oldPreTMS_orthographic_mismatches = oldPreTMS_orthographic.query(\"correct_resp == '4'\")\n",
    "    oldPreTMS_orthographic_mismatches = oldPreTMS_orthographic_mismatches.copy()\n",
    "    \n",
    "    oldPreTMS_false_font_matches = oldPreTMS_false_font.query(\"correct_resp == '3'\")\n",
    "    oldPreTMS_false_font_matches = oldPreTMS_false_font_matches.copy()\n",
    "    oldPreTMS_false_font_mismatches = oldPreTMS_false_font.query(\"correct_resp == '4'\")\n",
    "    oldPreTMS_false_font_mismatches = oldPreTMS_false_font_mismatches.copy()\n",
    "    \n",
    "    # post TMS trials\n",
    "    oldPostTMS = pd.concat([list4,list5,list6])\n",
    "    \n",
    "    oldPostTMS_phonological = oldPostTMS.query(\"condition == 'phonological'\")\n",
    "    oldPostTMS_orthographic = oldPostTMS.query(\"condition == 'orthographic'\")\n",
    "    oldPostTMS_false_font = oldPostTMS.query(\"condition == 'false_font'\")\n",
    "    \n",
    "    oldPostTMS_phonological_matches = oldPostTMS_phonological.query(\"correct_resp == '3'\")\n",
    "    oldPostTMS_phonological_matches = oldPostTMS_phonological_matches.copy()\n",
    "    oldPostTMS_phonological_mismatches = oldPostTMS_phonological.query(\"correct_resp == '4'\")\n",
    "    oldPostTMS_phonological_mismatches = oldPostTMS_phonological_mismatches.copy()\n",
    "    \n",
    "    oldPostTMS_orthographic_matches = oldPostTMS_orthographic.query(\"correct_resp == '3'\")\n",
    "    oldPostTMS_orthographic_matches = oldPostTMS_orthographic_matches.copy()\n",
    "    oldPostTMS_orthographic_mismatches = oldPostTMS_orthographic.query(\"correct_resp == '4'\")\n",
    "    oldPostTMS_orthographic_mismatches = oldPostTMS_orthographic_mismatches.copy()\n",
    "    \n",
    "    oldPostTMS_false_font_matches = oldPostTMS_false_font.query(\"correct_resp == '3'\")\n",
    "    oldPostTMS_false_font_matches = oldPostTMS_false_font_matches.copy()\n",
    "    oldPostTMS_false_font_mismatches = oldPostTMS_false_font.query(\"correct_resp == '4'\")\n",
    "    oldPostTMS_false_font_mismatches = oldPostTMS_false_font_mismatches.copy()\n",
    "    \n",
    "    #Make a set of files each for pre and post TMS runs\n",
    "    new_run1 = pd.DataFrame(columns=list1.columns)\n",
    "    new_run2 = pd.DataFrame(columns=list1.columns)\n",
    "    new_run3 = pd.DataFrame(columns=list1.columns)\n",
    "    new_run4 = pd.DataFrame(columns=list1.columns)\n",
    "    new_run5 = pd.DataFrame(columns=list1.columns)\n",
    "    new_run6 = pd.DataFrame(columns=list1.columns)\n",
    "    \n",
    "    conditions = [\"false_font\",\"phonological\",\"orthographic\"]\n",
    "    for condition in conditions:\n",
    "        random_options = [\"balanced\",\"3_matches\",\"3_mismatches\"]\n",
    "        if condition == \"false_font\":\n",
    "            contexts = ff_contexts\n",
    "            random_options = [\"3_matches\",\"3_mismatches\"]\n",
    "        elif condition == \"phonological\":\n",
    "            contexts = rw_contexts\n",
    "        elif condition == \"orthographic\":\n",
    "            contexts = rw_contexts\n",
    "        random.shuffle(contexts)\n",
    "        \n",
    "        if condition == \"phonological\":\n",
    "            pre_matches = oldPreTMS_phonological_matches\n",
    "            pre_mismatches = oldPreTMS_phonological_mismatches\n",
    "            post_matches = oldPostTMS_phonological_matches\n",
    "            post_mismatches = oldPostTMS_phonological_mismatches\n",
    "        elif condition == \"orthographic\":\n",
    "            pre_matches = oldPreTMS_orthographic_matches\n",
    "            pre_mismatches = oldPreTMS_orthographic_mismatches\n",
    "            post_matches = oldPostTMS_orthographic_matches\n",
    "            post_mismatches = oldPostTMS_orthographic_mismatches\n",
    "        elif condition == \"false_font\":\n",
    "            pre_matches = oldPreTMS_false_font_matches\n",
    "            pre_mismatches = oldPreTMS_false_font_mismatches\n",
    "            post_matches = oldPostTMS_false_font_matches\n",
    "            post_mismatches = oldPostTMS_false_font_mismatches\n",
    "        \n",
    "        random.shuffle(random_options) \n",
    "        for context in contexts: # for each of the three contexts, e.g. cvc_only\n",
    "            randomisation = random_options[0]\n",
    "            del random_options[0]\n",
    "            \n",
    "            pre_matches.reset_index(drop=True,inplace=True)\n",
    "            pre_mismatches.reset_index(drop=True,inplace=True)\n",
    "            post_matches.reset_index(drop=True,inplace=True)\n",
    "            post_matches.reset_index(drop=True,inplace=True)\n",
    "            \n",
    "            new_run1.loc[len(new_run1)] = [1,1,1,\"fixation\",\"fixation\",\"fixation\",\"fixation\",\"fixation\",0,1]\n",
    "            new_run2.loc[len(new_run1)] = [1,1,1,\"fixation\",\"fixation\",\"fixation\",\"fixation\",\"fixation\",0,1]\n",
    "            new_run3.loc[len(new_run1)] = [1,1,1,\"fixation\",\"fixation\",\"fixation\",\"fixation\",\"fixation\",0,1]\n",
    "            new_run4.loc[len(new_run1)] = [1,1,1,\"fixation\",\"fixation\",\"fixation\",\"fixation\",\"fixation\",0,1]\n",
    "            new_run5.loc[len(new_run1)] = [1,1,1,\"fixation\",\"fixation\",\"fixation\",\"fixation\",\"fixation\",0,1]\n",
    "            new_run6.loc[len(new_run1)] = [1,1,1,\"fixation\",\"fixation\",\"fixation\",\"fixation\",\"fixation\",0,1]\n",
    "            \n",
    "            new_run1.reset_index(drop=True,inplace=True)\n",
    "            new_run2.reset_index(drop=True,inplace=True)\n",
    "            new_run3.reset_index(drop=True,inplace=True)\n",
    "            new_run4.reset_index(drop=True,inplace=True)\n",
    "            new_run5.reset_index(drop=True,inplace=True)\n",
    "            new_run6.reset_index(drop=True,inplace=True)\n",
    "            \n",
    "            if randomisation == \"balanced\":\n",
    "                new_run1 = pd.concat([new_run1,pre_matches.iloc[:2]]) #append 2 matching trials\n",
    "                new_run1 = pd.concat([new_run1,pre_mismatches.iloc[:2]]) #append 2 mismatching trials\n",
    "                pre_matches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                pre_mismatches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                pre_matches.reset_index(drop=True,inplace=True)\n",
    "                pre_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run2 = pd.concat([new_run2,pre_matches.iloc[:3]]) #append 3 matching trials\n",
    "                new_run2 = pd.concat([new_run2,pre_mismatches.iloc[:1]]) #append 1 mismatching trials\n",
    "                pre_matches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                pre_mismatches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                pre_matches.reset_index(drop=True,inplace=True)\n",
    "                pre_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run3 = pd.concat([new_run3,pre_matches.iloc[:1]]) #append 1 matching trials\n",
    "                new_run3 = pd.concat([new_run3,pre_mismatches.iloc[:3]]) #append 3 mismatching trials\n",
    "                pre_matches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                pre_mismatches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                pre_matches.reset_index(drop=True,inplace=True)\n",
    "                pre_mismatches.reset_index(drop=True,inplace=True)\n",
    "                \n",
    "                new_run4 = pd.concat([new_run4,post_matches.iloc[:2]]) #append 2 matching trials\n",
    "                new_run4 = pd.concat([new_run4,post_mismatches.iloc[:2]]) #append 2 mismatching trials\n",
    "                post_matches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                post_mismatches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                post_matches.reset_index(drop=True,inplace=True)\n",
    "                post_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run5 = pd.concat([new_run5,post_matches.iloc[:3]]) #append 3 matching trials\n",
    "                new_run5 = pd.concat([new_run5,post_mismatches.iloc[:1]]) #append 1 mismatching trials\n",
    "                post_matches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                post_mismatches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                post_matches.reset_index(drop=True,inplace=True)\n",
    "                post_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run6 = pd.concat([new_run6,post_matches.iloc[:1]]) #append 1 matching trials\n",
    "                new_run6 = pd.concat([new_run6,post_mismatches.iloc[:3]]) #append 3 mismatching trials\n",
    "                post_matches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                post_mismatches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                post_matches.reset_index(drop=True,inplace=True)\n",
    "                post_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "            elif randomisation == \"3_matches\":\n",
    "                new_run1 = pd.concat([new_run1,pre_matches.iloc[:3]]) #append 3 matching trials\n",
    "                new_run1 = pd.concat([new_run1,pre_mismatches.iloc[:1]]) #append 1 mismatching trials\n",
    "                pre_matches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                pre_mismatches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                pre_matches.reset_index(drop=True,inplace=True)\n",
    "                pre_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run2 = pd.concat([new_run2,pre_matches.iloc[:1]]) #append 1 matching trials\n",
    "                new_run2 = pd.concat([new_run2,pre_mismatches.iloc[:3]]) #append 3 mismatching trials\n",
    "                pre_matches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                pre_mismatches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                pre_matches.reset_index(drop=True,inplace=True)\n",
    "                pre_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run3 = pd.concat([new_run3,pre_matches.iloc[:2]]) #append 2 matching trials\n",
    "                new_run3 = pd.concat([new_run3,pre_mismatches.iloc[:2]]) #append 2 mismatching trials\n",
    "                pre_matches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                pre_mismatches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                pre_matches.reset_index(drop=True,inplace=True)\n",
    "                pre_mismatches.reset_index(drop=True,inplace=True)\n",
    "                \n",
    "                new_run4 = pd.concat([new_run4,post_matches.iloc[:3]]) #append 3 matching trials\n",
    "                new_run4 = pd.concat([new_run4,post_mismatches.iloc[:1]]) #append 1 mismatching trials\n",
    "                post_matches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                post_mismatches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                post_matches.reset_index(drop=True,inplace=True)\n",
    "                post_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run5 = pd.concat([new_run5,post_matches.iloc[:1]]) #append 1 matching trials\n",
    "                new_run5 = pd.concat([new_run5,post_mismatches.iloc[:3]]) #append 3 mismatching trials\n",
    "                post_matches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                post_mismatches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                post_matches.reset_index(drop=True,inplace=True)\n",
    "                post_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run6 = pd.concat([new_run6,post_matches.iloc[:2]]) #append 2 matching trials\n",
    "                new_run6 = pd.concat([new_run6,post_mismatches.iloc[:2]]) #append 2 mismatching trials\n",
    "                post_matches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                post_mismatches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                post_matches.reset_index(drop=True,inplace=True)\n",
    "                post_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "            elif randomisation == \"3_mismatches\":\n",
    "                new_run1 = pd.concat([new_run1,pre_matches.iloc[:1]]) #append 1 matching trials\n",
    "                new_run1 = pd.concat([new_run1,pre_mismatches.iloc[:3]]) #append 3 mismatching trials\n",
    "                pre_matches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                pre_mismatches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                pre_matches.reset_index(drop=True,inplace=True)\n",
    "                pre_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run2 = pd.concat([new_run2,pre_matches.iloc[:2]]) #append 2 matching trials\n",
    "                new_run2 = pd.concat([new_run2,pre_mismatches.iloc[:2]]) #append 2 mismatching trials\n",
    "                pre_matches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                pre_mismatches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                pre_matches.reset_index(drop=True,inplace=True)\n",
    "                pre_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run3 = pd.concat([new_run3,pre_matches.iloc[:3]]) #append 3 matching trials\n",
    "                new_run3 = pd.concat([new_run3,pre_mismatches.iloc[:1]]) #append 1 mismatching trials\n",
    "                pre_matches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                pre_mismatches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                pre_matches.reset_index(drop=True,inplace=True)\n",
    "                pre_mismatches.reset_index(drop=True,inplace=True)\n",
    "                \n",
    "                new_run4 = pd.concat([new_run4,post_matches.iloc[:1]]) #append 1 matching trials\n",
    "                new_run4 = pd.concat([new_run4,post_mismatches.iloc[:3]]) #append 3 mismatching trials\n",
    "                post_matches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                post_mismatches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                post_matches.reset_index(drop=True,inplace=True)\n",
    "                post_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run5 = pd.concat([new_run5,post_matches.iloc[:2]]) #append 2 matching trials\n",
    "                new_run5 = pd.concat([new_run5,post_mismatches.iloc[:2]]) #append 2 mismatching trials\n",
    "                post_matches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                post_mismatches.drop([0,1], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                post_matches.reset_index(drop=True,inplace=True)\n",
    "                post_mismatches.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                new_run6 = pd.concat([new_run6,post_matches.iloc[:3]]) #append 3 matching trials\n",
    "                new_run6 = pd.concat([new_run6,post_mismatches.iloc[:1]]) #append 1 mismatching trials\n",
    "                post_matches.drop([0,1,2], inplace=True) #drop used rows from orig frame\n",
    "                post_mismatches.drop([0], inplace=True) #drop used rows from orig frame\n",
    "                \n",
    "                post_matches.reset_index(drop=True,inplace=True)\n",
    "                post_mismatches.reset_index(drop=True,inplace=True)\n",
    "            \n",
    "            \n",
    "            new_run1.reset_index(drop=True,inplace=True)\n",
    "            new_run2.reset_index(drop=True,inplace=True)\n",
    "            new_run3.reset_index(drop=True,inplace=True)\n",
    "            new_run4.reset_index(drop=True,inplace=True)\n",
    "            new_run5.reset_index(drop=True,inplace=True)\n",
    "            new_run6.reset_index(drop=True,inplace=True)\n",
    "            \n",
    "            # change context labels\n",
    "            new_run1.iloc[-4:, 5] = context\n",
    "            new_run2.iloc[-4:, 5] = context\n",
    "            new_run3.iloc[-4:, 5] = context\n",
    "            new_run4.iloc[-4:, 5] = context\n",
    "            new_run5.iloc[-4:, 5] = context\n",
    "            new_run6.iloc[-4:, 5] = context\n",
    "    \n",
    "    # For every session, shuffle the condition presentation order\n",
    "    block1 = [0,1,2,3,4]\n",
    "    block2 = [5,6,7,8,9]\n",
    "    block3 = [10,11,12,13,14]\n",
    "    block4 = [15,16,17,18,19]\n",
    "    block5 = [20,21,22,23,24]\n",
    "    block6 = [25,26,27,28,29]\n",
    "    block7 = [30,31,32,33,34]\n",
    "    block8 = [35,36,37,38,39]\n",
    "    \n",
    "    b1 = block1[1:]\n",
    "    b2 = block2[1:]\n",
    "    b3 = block3[1:]\n",
    "    b4 = block4[1:]\n",
    "    b5 = block5[1:]\n",
    "    b6 = block6[1:]\n",
    "    b7 = block7[1:]\n",
    "    b8 = block8[1:]\n",
    "    random.shuffle(b1)\n",
    "    random.shuffle(b2)\n",
    "    random.shuffle(b3)\n",
    "    random.shuffle(b4)\n",
    "    random.shuffle(b5)\n",
    "    random.shuffle(b6)\n",
    "    random.shuffle(b7)\n",
    "    random.shuffle(b8)\n",
    "    \n",
    "    block1[1:] = b1\n",
    "    block2[1:] = b2\n",
    "    block3[1:] = b3\n",
    "    block4[1:] = b4\n",
    "    block5[1:] = b5\n",
    "    block6[1:] = b6\n",
    "    block7[1:] = b7\n",
    "    block8[1:] = b8\n",
    "\n",
    "    blocks = [block1,block2,block3,block4,block5,block6,block7,block8]\n",
    "    random.shuffle(blocks)\n",
    "    new_index1 = blocks.copy()\n",
    "    random.shuffle(blocks)\n",
    "    new_index2 = blocks.copy()\n",
    "    random.shuffle(blocks)\n",
    "    new_index3 = blocks.copy()\n",
    "    random.shuffle(blocks)\n",
    "    new_index4 = blocks.copy()\n",
    "    random.shuffle(blocks)\n",
    "    new_index5 = blocks.copy()\n",
    "    random.shuffle(blocks)\n",
    "    new_index6 = blocks.copy()\n",
    "\n",
    "    new_index1_flat = [val for sublist in new_index1 for val in sublist]\n",
    "    new_index2_flat = [val for sublist in new_index2 for val in sublist]\n",
    "    new_index3_flat = [val for sublist in new_index3 for val in sublist]\n",
    "    new_index4_flat = [val for sublist in new_index4 for val in sublist]\n",
    "    new_index5_flat = [val for sublist in new_index5 for val in sublist]\n",
    "    new_index6_flat = [val for sublist in new_index6 for val in sublist]\n",
    "\n",
    "    new_run1 = new_run1.reindex(new_index1_flat)\n",
    "    new_run2 = new_run2.reindex(new_index2_flat)\n",
    "    new_run3 = new_run3.reindex(new_index3_flat)\n",
    "    new_run4 = new_run4.reindex(new_index4_flat)\n",
    "    new_run5 = new_run5.reindex(new_index5_flat)\n",
    "    new_run6 = new_run6.reindex(new_index6_flat)\n",
    "    \n",
    "    new_run1.reset_index(drop=True,inplace=True)\n",
    "    new_run2.reset_index(drop=True,inplace=True)\n",
    "    new_run3.reset_index(drop=True,inplace=True)\n",
    "    new_run4.reset_index(drop=True,inplace=True)\n",
    "    new_run5.reset_index(drop=True,inplace=True)\n",
    "    new_run6.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    #fix trial, run and block columns\n",
    "    new_run1.iloc[:,[0,1,2,9]] = list1.iloc[:,[0,1,2,9]]\n",
    "    new_run2.iloc[:,[0,1,2,9]] = list2.iloc[:,[0,1,2,9]]\n",
    "    new_run3.iloc[:,[0,1,2,9]] = list3.iloc[:,[0,1,2,9]]\n",
    "    new_run4.iloc[:,[0,1,2,9]] = list4.iloc[:,[0,1,2,9]]\n",
    "    new_run5.iloc[:,[0,1,2,9]] = list5.iloc[:,[0,1,2,9]]\n",
    "    new_run6.iloc[:,[0,1,2,9]] = list6.iloc[:,[0,1,2,9]]\n",
    "    \n",
    "    #Save csv files... trials_sesX_runX.csv\n",
    "    start_path = \"/Users/nikola/NikolaCloud/Projects/Research Projects/2018 - UCSF/R01_Dyslexia_TMS/3_experiment/1_collection/TMS_PhonOrtho_Task/trial_list/\"\n",
    "    new_run1.to_csv(start_path+\"/trials_ses\"+session+\"_run1.csv\",index=False)\n",
    "    new_run2.to_csv(start_path+\"/trials_ses\"+session+\"_run2.csv\",index=False)\n",
    "    new_run3.to_csv(start_path+\"/trials_ses\"+session+\"_run3.csv\",index=False)\n",
    "    new_run4.to_csv(start_path+\"/trials_ses\"+session+\"_run4.csv\",index=False)\n",
    "    new_run5.to_csv(start_path+\"/trials_ses\"+session+\"_run5.csv\",index=False)\n",
    "    new_run6.to_csv(start_path+\"/trials_ses\"+session+\"_run6.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
